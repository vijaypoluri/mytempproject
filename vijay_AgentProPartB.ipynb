{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vijaypoluri/mytempproject/blob/main/vijay_AgentProPartB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installing several Python libraries that are useful for AI-powered search, transcription, web scraping, and presentation generation. Here's what each package does:\n",
        "\n",
        "1. openai\n",
        "Official OpenAI library for interacting with GPT models (e.g., GPT-4o).\n",
        "Used for generating text, code, chatbots, etc.\n",
        "2. youtube_transcript_api\n",
        "Fetches YouTube video transcripts (captions) automatically.\n",
        "Useful for speech-to-text analysis, summarization, and sentiment analysis.\n",
        "3. duckduckgo-search\n",
        "Allows privacy-focused web searches using DuckDuckGo.\n",
        "Useful for scraping news, articles, and general web content without tracking.\n",
        "4. requests\n",
        "A widely used library for making HTTP requests.\n",
        "Used for fetching data from web APIs (e.g., OpenAI, stock market data, etc.).\n",
        "5. python-pptx\n",
        "A library for creating and modifying PowerPoint (.pptx) presentations.\n",
        "Useful for automating reports, AI-generated slides, and visual presentations."
      ],
      "metadata": {
        "id": "LNkiiREEV4Ur"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "RmRE4vZuUyM_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f844e4e-e439-49e0-ad49-0af73c4f19ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m472.8/472.8 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m165.1/165.1 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install openai youtube_transcript_api duckduckgo-search requests python-pptx --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "import subprocess\n",
        "import tempfile\n",
        "import re\n",
        "import importlib\n",
        "import sys\n",
        "import os\n",
        "from urllib.parse import urlparse, parse_qs\n",
        "import json"
      ],
      "metadata": {
        "id": "U1th2q6FVJtT"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
        "os.environ[\"TRAVERSAAL_ARES_API_KEY\"] = userdata.get('TRAVERSAAL_ARES_API_KEY')"
      ],
      "metadata": {
        "id": "IKYNa4kDVKF6"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "V7m4maV1l5gw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tool Base Class"
      ],
      "metadata": {
        "id": "qRYVrNidl6EY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Any\n",
        "from abc import ABC, abstractmethod\n",
        "from pydantic import BaseModel, ConfigDict\n",
        "\n",
        "\n",
        "class Tool(ABC, BaseModel):\n",
        "  name: str\n",
        "  description: str\n",
        "  arg: str\n",
        "\n",
        "  def model_post_init(self, __context: Any) -> None:\n",
        "    self.name = self.name.lower().replace(' ', '_')\n",
        "    self.description = self.description.lower()\n",
        "    self.arg = self.arg.lower()\n",
        "\n",
        "  @abstractmethod\n",
        "  def run(self, prompt: str) -> str:\n",
        "    pass\n",
        "\n",
        "  def get_tool_description(self):\n",
        "    return f\"Tool: {self.name}\\nDescription: {self.description}\\nArg: {self.arg}\\n\"\n",
        "\n",
        "class LLMTool(Tool):\n",
        "  client: Any = OpenAI(api_key=os.environ[\"OPENAI_API_KEY\"])"
      ],
      "metadata": {
        "id": "a9dlKyNLVNKe"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AvhqvHv3gtBZ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ares Internet Search Tool"
      ],
      "metadata": {
        "id": "spg9Jjc8b4zu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from pydantic import HttpUrl\n",
        "\n",
        "class AresInternetTool(Tool):\n",
        "  name: str = \"Ares Internet Search Tool\"\n",
        "  description: str = \"Tool to search real-time relevant content from the internet\"\n",
        "  arg: str = \"A single string parameter that will be searched on the internet to find relevant content\"\n",
        "\n",
        "  # Specific Parameters\n",
        "  url : HttpUrl = \"https://api-ares.traversaal.ai/live/predict\"\n",
        "  x_api_key: str = os.environ[\"TRAVERSAAL_ARES_API_KEY\"]\n",
        "\n",
        "  def run(self, prompt: str) -> str:\n",
        "    print(f\"Calling Ares Internet Search Tool with prompt: {prompt}\")\n",
        "    payload = {\"query\": [prompt]}\n",
        "    response = requests.post(self.url, json=payload, headers={\n",
        "        \"x-api-key\": self.x_api_key,\n",
        "        \"content-type\": \"application/json\"\n",
        "    })\n",
        "    if response.status_code != 200:\n",
        "        return f\"Error: {response.status_code} - {response.text}\"\n",
        "    response = response.json()\n",
        "    return response['data']['response_text']"
      ],
      "metadata": {
        "id": "06ZzHUn0WQo5"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Code Engine Tool"
      ],
      "metadata": {
        "id": "vH0pxz7Ob7-D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CodeEngine(LLMTool):\n",
        "\n",
        "  name: str = \"Code Generation and Execution Tool\"\n",
        "  description: str = \"A coding tool that can take a prompt and generate executable Python code. It parses and executes the code. Returns the code and the error if the code execution fails.\"\n",
        "  arg: str = \"A single string parameter describing the coding task.\"\n",
        "\n",
        "  def parse_and_exec_code(self, response: str):\n",
        "    result = re.search(r'```python\\s*([\\s\\S]*?)\\s*```', response)\n",
        "    code_string = result.group(1)\n",
        "    if \"pip install\" in code_string.split(\"\\n\")[0]:\n",
        "      print(\"Requires PIP package installations\")\n",
        "      packages = code_string.split(\"\\n\")[0].split(\"pip install\")[-1].strip()\n",
        "      if \",\" in packages:\n",
        "        packages = packages.split(\",\")\n",
        "      elif \" \" in packages:\n",
        "        packages = packages.split(\" \")\n",
        "      else:\n",
        "        packages = [packages]\n",
        "      print(f\"Installing packages: {packages}\")\n",
        "      for package in packages:\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
        "\n",
        "    # Execute main code\n",
        "    print(\"Executing main code...\")\n",
        "    try:\n",
        "      exec(code_string)\n",
        "    except Exception as e:\n",
        "      print(f\"Error executing generated code: {e}\")\n",
        "      return code_string, e\n",
        "    return code_string, None\n",
        "\n",
        "  def generate_code(self, prompt):\n",
        "    response = self.client.chat.completions.create(\n",
        "      model=\"gpt-4o\",\n",
        "      messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a Python code generator. Respond only with executable Python code, no explanations or comments except for required pip installations at the top. Return the code within ```python and ``` strings. The first line should be commented out pip install statement\"},\n",
        "        {\"role\": \"user\", \"content\": f\"Generate Python code to {prompt}. If you need to use any external libraries, include a comment at the top of the code listing the required pip installations.\"}\n",
        "      ],\n",
        "      max_tokens=4000,\n",
        "      temperature=0.7\n",
        "    )\n",
        "    response = response.choices[0].message.content\n",
        "    code, error = self.parse_and_exec_code(response)\n",
        "    return code, error\n",
        "\n",
        "  def run(self, prompt: str) -> str:\n",
        "    print(f\"Calling Code Generaton Tool with the prompt: {prompt}\")\n",
        "    code, error = self.generate_code(prompt)\n",
        "    if error:\n",
        "      return f\"Code: {code}\\n\\nCode execution caused an error: {error}\"\n",
        "    return f\"Code: {code}\\n\\n\\nCode Executed Successfully\"\n"
      ],
      "metadata": {
        "id": "Z7GMTQv3ajZF"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## YouTube Search Tool"
      ],
      "metadata": {
        "id": "sc4sNN3Xb938"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from youtube_transcript_api import YouTubeTranscriptApi\n",
        "from duckduckgo_search import DDGS"
      ],
      "metadata": {
        "id": "z4g6yjFfcHvo"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class YouTubeSearchTool(LLMTool):\n",
        "  name: str = \"YouTube Search Tool\"\n",
        "  description: str = \"A tool capable of searching the internet for youtube videos and returns the text transcript of the videos\"\n",
        "  arg: str = \"A single string parameter that will be searched on the internet to find relevant content\"\n",
        "  # Specific Parameters\n",
        "  ddgs : Any = DDGS()\n",
        "\n",
        "  def extract_video_id(self, url):\n",
        "      \"\"\"Extract video ID from YouTube URL.\"\"\"\n",
        "      parsed_url = urlparse(url)\n",
        "      if parsed_url.hostname in ['www.youtube.com', 'youtube.com']:\n",
        "          if parsed_url.path == '/watch':\n",
        "              return parse_qs(parsed_url.query)['v'][0]\n",
        "          elif parsed_url.path.startswith('/shorts/'):\n",
        "              return parsed_url.path.split('/')[2]\n",
        "      elif parsed_url.hostname == 'youtu.be':\n",
        "          return parsed_url.path[1:]\n",
        "      return None\n",
        "\n",
        "  def search_videos(self, query, max_results=5):\n",
        "      \"\"\"Search YouTube videos using DuckDuckGo.\"\"\"\n",
        "      try:\n",
        "          # Search for videos using DDG videos search\n",
        "          results = self.ddgs.videos(\n",
        "              keywords=query,\n",
        "              region=\"wt-wt\",\n",
        "              safesearch=\"off\",\n",
        "              timelimit=\"w\",\n",
        "              resolution=\"high\",\n",
        "              duration=\"medium\",\n",
        "              max_results=max_results*2 # Get 2x required results so get some relevant results. Sort and Filter later.\n",
        "          )\n",
        "\n",
        "          results = sorted(\n",
        "              results,\n",
        "              key=lambda x: (\n",
        "                  -(x['statistics']['viewCount'] if x['statistics']['viewCount'] is not None else float('-inf')) # Sort -> More Views First\n",
        "              )\n",
        "          )[:max_results]\n",
        "\n",
        "          videos = []\n",
        "          for result in results:\n",
        "              video_url = result.get('content')  # The actual video URL is in the 'content' field\n",
        "              video_id = self.extract_video_id(video_url)\n",
        "              if video_id:\n",
        "                  video_data = {\n",
        "                      'title': result['title'],\n",
        "                      'video_id': video_id,\n",
        "                      'description': result.get('description', ''),\n",
        "                      'link': video_url,\n",
        "                      'duration': result.get('duration', ''),\n",
        "                      'publisher': result.get('publisher', ''),\n",
        "                      'uploader': result.get('uploader', ''),\n",
        "                      'published': result.get('published', ''),\n",
        "                      'view_count': result.get('statistics', {}).get('viewCount', 'N/A'),\n",
        "                      'thumbnail': result.get('images', {}).get('large', '')\n",
        "                  }\n",
        "                  videos.append(video_data)\n",
        "\n",
        "          if not videos:\n",
        "              return \"No YouTube videos found in the search results.\"\n",
        "\n",
        "          return videos[:max_results]\n",
        "      except Exception as e:\n",
        "          return f\"Error searching videos: {str(e)}\"\n",
        "\n",
        "  def get_transcript(self, video_id):\n",
        "        \"\"\"Get transcript for a YouTube video.\"\"\"\n",
        "        try:\n",
        "            transcript_list = YouTubeTranscriptApi.get_transcript(video_id)\n",
        "            return ' '.join([entry['text'] for entry in transcript_list])\n",
        "        except Exception as e:\n",
        "            print(f\"Error getting transcript: {str(e)}\")\n",
        "            return None\n",
        "\n",
        "  def summarize_content(self, transcript):\n",
        "      prompt = \"Create a concise summary of the following video transcript\"\n",
        "\n",
        "      try:\n",
        "          response = self.client.chat.completions.create(\n",
        "              model=\"gpt-4\",\n",
        "              messages=[\n",
        "                  {\"role\": \"system\", \"content\": \"You are an expert content creator specializing in creating high-quality content from video transcripts.\"},\n",
        "                  {\"role\": \"user\", \"content\": f\"{prompt}\\n\\nTranscript:\\n{transcript}\"}\n",
        "              ],\n",
        "              max_tokens=2000\n",
        "          )\n",
        "          return response.choices[0].message.content.strip()\n",
        "      except Exception as e:\n",
        "          return None\n",
        "\n",
        "\n",
        "  def run(self, prompt: str) -> str:\n",
        "      print(f\"Calling YouTube Search Tool with prompt: {prompt}\")\n",
        "      try:\n",
        "          # Parse the prompt for parameters\n",
        "\n",
        "          # Search for videos\n",
        "          # print(f\"Searching for videos about: {params['query']}\")\n",
        "          videos = self.search_videos(prompt, 3)\n",
        "\n",
        "          if isinstance(videos, str):  # Error occurred\n",
        "              return f\"Search error: {videos}\"\n",
        "\n",
        "          if not videos:  # No videos found\n",
        "              return \"No videos found matching the query.\"\n",
        "\n",
        "          results = []\n",
        "          for video in videos:\n",
        "              # print(f\"\\nProcessing video: {video['title']}\")\n",
        "              # print(f\"By: {video['uploader']}\")\n",
        "              # print(f\"URL: {video['link']}\")\n",
        "              # print(f\"Duration: {video['duration']}\")\n",
        "              # print(f\"Views: {video['view_count']}\")\n",
        "              # print(f\"Published: {video['published']}\")\n",
        "\n",
        "              # Get transcript\n",
        "              transcript = self.get_transcript(video['video_id'])\n",
        "              if not transcript:\n",
        "                  continue\n",
        "\n",
        "              content = self.summarize_content(transcript)\n",
        "              results.append({\n",
        "                  \"video\": video,\n",
        "                  \"content\": content.replace(\"\\n\\n\", \"\\n\").replace(\"\\n\\n\\n\", \"\\n\")\n",
        "              })\n",
        "\n",
        "          if not results:\n",
        "              return \"Could not process any videos. Try a different search query.\"\n",
        "          results = list(map(lambda x: f\"Video Title: {x['video']}\\nContent: {x['content']}\", results))\n",
        "          return \"\\n\\n\\n\".join(results)\n",
        "\n",
        "      except Exception as e:\n",
        "          return f\"Error executing task: {str(e)}\""
      ],
      "metadata": {
        "id": "cBKmsLXVawIh"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Slide Generation Tool"
      ],
      "metadata": {
        "id": "u_IJB7tueUu-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pptx import Presentation\n",
        "from typing import List, Dict"
      ],
      "metadata": {
        "id": "GxuXQVvpfeGW"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SlideGenerationTool(Tool):\n",
        "    name: str = \"Slide Generation Tool\"\n",
        "    description: str = \"A tool that can create a PPTX deck for a content. It takes a list of dictionaries. Each list dictionary item represents a slide in the presentation. Each dictionary item must have two keys: 'slide_title' and 'content'.\"\n",
        "    arg: str = \"List[Dict[slide_title, content]]. Ensure the Action Input is JSON parseable so I can convert it to required format\"\n",
        "\n",
        "    def run(self, slide_content: List[Dict[str, str]]) -> str:\n",
        "        print(f\"Calling Slide Generation Tool with slide_content TYPE :{type(slide_content)}\")\n",
        "        if type(slide_content) == str:\n",
        "          try:\n",
        "            slide_content = json.loads(slide_content)\n",
        "            print(\"Converted Slide Content from str to JSON Dictionary\")\n",
        "          except Exception as e:\n",
        "            return f\"Error: {e}\"\n",
        "        presentation = Presentation()\n",
        "\n",
        "        # Iterate over the slides list and add content to the presentation\n",
        "        for slide in slide_content:\n",
        "            # Add a slide with a title and content layout\n",
        "            slide_layout = presentation.slide_layouts[1]  # Layout 1 is 'Title and Content'\n",
        "            ppt_slide = presentation.slides.add_slide(slide_layout)\n",
        "\n",
        "            # Set the title and content for the slide\n",
        "            title = ppt_slide.shapes.title\n",
        "            content = ppt_slide.placeholders[1]\n",
        "\n",
        "            title.text = slide['slide_title']\n",
        "            content.text = slide['content']\n",
        "\n",
        "        # Save the presentation to the specified output file\n",
        "        presentation.save(\"presentation.pptx\")\n",
        "        return f\"Presentation saved as 'presentation.pptx'.\""
      ],
      "metadata": {
        "id": "gqMnPkDmeWXq"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Agent"
      ],
      "metadata": {
        "id": "jpIu4C92fy7G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "REACT_AGENT_SYSTEM_PROMPT = \"\"\"\n",
        "Answer the following questions as best you can. You have access to the following tools:\n",
        "\n",
        "{tools}\n",
        "\n",
        "Use the following format:\n",
        "\n",
        "Question: the input question you must answer\n",
        "Thought: you should always think about what to do\n",
        "Action: the action to take, should be one of [{tool_names}]\n",
        "Action Input: the input to the action\n",
        "Observation: the result of the action\n",
        "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
        "Thought: I now know the final answer\n",
        "Final Answer: the final answer to the original input question\n",
        "\n",
        "Begin!\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "56LnjjQEgHXz"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AgentPro:\n",
        "    def __init__(self, llm = OpenAI(), tools: List[Tool] = [], system_prompt: str = None, react_prompt: str = REACT_AGENT_SYSTEM_PROMPT):\n",
        "        super().__init__()\n",
        "        self.client = llm\n",
        "        self.tools = self.format_tools(tools)\n",
        "        self.react_prompt = react_prompt.format(\n",
        "            tools=\"\\n\\n\".join(map(lambda tool: tool.get_tool_description(), tools)),\n",
        "            tool_names=\", \".join(map(lambda tool: tool.name, tools))\n",
        "        )\n",
        "        print(self.react_prompt)\n",
        "        self.messages = []\n",
        "        if system_prompt:\n",
        "            self.messages.append({\"role\": \"system\", \"content\": system_prompt})\n",
        "        self.messages.append({\"role\": \"system\", \"content\": self.react_prompt})\n",
        "\n",
        "    def format_tools(self, tools: List[Tool]) -> Dict:\n",
        "        tool_names = list(map(lambda tool: tool.name, tools))\n",
        "        return dict(zip(tool_names, tools))\n",
        "\n",
        "    def parse_action_string(self, text):\n",
        "        \"\"\"\n",
        "        Parses action and action input from a string containing thoughts and actions.\n",
        "        Handles multi-line actions and optional observations.\n",
        "        \"\"\"\n",
        "        lines = text.split('\\n')\n",
        "        action = None\n",
        "        action_input = []\n",
        "        is_action_input = False\n",
        "\n",
        "        for line in lines:\n",
        "            if line.startswith('Action:'):\n",
        "                action = line.replace('Action:', '').strip()\n",
        "                continue\n",
        "\n",
        "            if line.startswith('Action Input:'):\n",
        "                is_action_input = True\n",
        "                # Handle single-line action input\n",
        "                input_text = line.replace('Action Input:', '').strip()\n",
        "                if input_text:\n",
        "                    action_input.append(input_text)\n",
        "                continue\n",
        "\n",
        "            if line.startswith('Observation:'):\n",
        "                is_action_input = False\n",
        "                continue\n",
        "\n",
        "            # Collect multi-line action input\n",
        "            if is_action_input and line.strip():\n",
        "                action_input.append(line.strip())\n",
        "\n",
        "        # Join multi-line action input\n",
        "        action_input = '\\n'.join(action_input)\n",
        "        try:\n",
        "          action_input = json.loads(action_input)\n",
        "        except Exception as e:\n",
        "          pass\n",
        "        return action, action_input\n",
        "\n",
        "    def tool_call(self, response):\n",
        "        action, action_input = self.parse_action_string(response)\n",
        "        try:\n",
        "          if action.strip().lower() in self.tools:\n",
        "            tool_observation = self.tools[action].run(action_input)\n",
        "            return f\"Observation: {tool_observation}\"\n",
        "        except Exception as e:\n",
        "          return f\"Obeservation: There was an error executing the tool\\nError: {e}\"\n",
        "\n",
        "    def __call__(self, prompt):\n",
        "        self.messages.append(\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        )\n",
        "        response = \"\"\n",
        "        while True:\n",
        "            response = self.client.chat.completions.create(\n",
        "                    model=\"gpt-4\",\n",
        "                    messages=self.messages,\n",
        "                    max_tokens=2000\n",
        "                ).choices[0].message.content.strip()\n",
        "            self.messages.append({\"role\":\"assistant\", \"content\": response})\n",
        "            print(\"=\"*80)\n",
        "            if \"Final Answer\" in response:\n",
        "              return response.split(\"Final Answer:\")[-1].strip()\n",
        "            print(response)\n",
        "            print(\"=\"*80)\n",
        "            if \"Action\" in response and \"Action Input\" in response:\n",
        "              observation = self.tool_call(response)\n",
        "              self.messages.append(\n",
        "                  {\"role\": \"assistant\", \"content\": observation}\n",
        "              )"
      ],
      "metadata": {
        "id": "kppG8_q5f5GI"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using Agent with Multiple Tools"
      ],
      "metadata": {
        "id": "zJdHbua5ixCs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ares_internet_tool = AresInternetTool()"
      ],
      "metadata": {
        "id": "ge-ytDdki1Uu"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yt_search_tool = YouTubeSearchTool()"
      ],
      "metadata": {
        "id": "1cRxI7YHi56n"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "code_tool = CodeEngine()"
      ],
      "metadata": {
        "id": "x90AJK2Si_D-"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "slide_generation_tool = SlideGenerationTool()"
      ],
      "metadata": {
        "id": "1XXAftuBfwTv"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tools = [\n",
        "    code_tool,\n",
        "    ares_internet_tool,\n",
        "    yt_search_tool,\n",
        "    slide_generation_tool,\n",
        "]"
      ],
      "metadata": {
        "id": "rU-eeP6hizHB"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent = AgentPro(tools=tools)"
      ],
      "metadata": {
        "id": "YgrOdu32inyN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d651769e-7bff-47f3-81f7-e853c5ccc42a"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Answer the following questions as best you can. You have access to the following tools:\n",
            "\n",
            "Tool: code_generation_and_execution_tool\n",
            "Description: a coding tool that can take a prompt and generate executable python code. it parses and executes the code. returns the code and the error if the code execution fails.\n",
            "Arg: a single string parameter describing the coding task.\n",
            "\n",
            "\n",
            "Tool: ares_internet_search_tool\n",
            "Description: tool to search real-time relevant content from the internet\n",
            "Arg: a single string parameter that will be searched on the internet to find relevant content\n",
            "\n",
            "\n",
            "Tool: youtube_search_tool\n",
            "Description: a tool capable of searching the internet for youtube videos and returns the text transcript of the videos\n",
            "Arg: a single string parameter that will be searched on the internet to find relevant content\n",
            "\n",
            "\n",
            "Tool: slide_generation_tool\n",
            "Description: a tool that can create a pptx deck for a content. it takes a list of dictionaries. each list dictionary item represents a slide in the presentation. each dictionary item must have two keys: 'slide_title' and 'content'.\n",
            "Arg: list[dict[slide_title, content]]. ensure the action input is json parseable so i can convert it to required format\n",
            "\n",
            "\n",
            "Use the following format:\n",
            "\n",
            "Question: the input question you must answer\n",
            "Thought: you should always think about what to do\n",
            "Action: the action to take, should be one of [code_generation_and_execution_tool, ares_internet_search_tool, youtube_search_tool, slide_generation_tool]\n",
            "Action Input: the input to the action\n",
            "Observation: the result of the action\n",
            "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
            "Thought: I now know the final answer\n",
            "Final Answer: the final answer to the original input question\n",
            "\n",
            "Begin!\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(agent.tools))\n",
        "print(agent.tools.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sxSiNesLMGfT",
        "outputId": "262a15a8-2c96-439f-c625-c68e7bff7413"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'dict'>\n",
            "dict_keys(['code_generation_and_execution_tool', 'ares_internet_search_tool', 'youtube_search_tool', 'slide_generation_tool'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test 1"
      ],
      "metadata": {
        "id": "wJPpns-z30lM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "agent(\"Generate a presentation deck on Supervised Fine-tuning. Add relevant images where applicable\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 524
        },
        "id": "s-uQr9GLjHQ1",
        "outputId": "04de2221-5c11-4669-f271-337c6d8b2d7f"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "Thought: To generate a presentation deck with relevant images, I first need to gather content and find suitable images on the topic 'Supervised Fine-tuning'. I will start by using the ares_internet_search_tool to find relevant information and images.\n",
            "Action: ares_internet_search_tool\n",
            "Action Input: \"Supervised Fine-tuning images\"\n",
            "================================================================================\n",
            "Calling Ares Internet Search Tool with prompt: Supervised Fine-tuning images\n",
            "================================================================================\n",
            "Thought: Now that I have collected the information to be included in the deck, I can use the slide_generation_tool to create the presentation. However, to include relevant images, I'll search for freely usable images that I can manually add to the slides.\n",
            "Action: ares_internet_search_tool\n",
            "Action Input: \"Freely usable images for Supervised Fine-Tuning presentation\"\n",
            "================================================================================\n",
            "Calling Ares Internet Search Tool with prompt: Freely usable images for Supervised Fine-Tuning presentation\n",
            "================================================================================\n",
            "Thought: Now that I have a source for images, I can now create the slide deck. Note: the actual image embedding will have to be carried out manually as my capabilities as an AI assistant currently do not enable handling dynamic image data. In each slide description, I will add a note where the user can add an image from the suggested sources. \n",
            "Action: slide_generation_tool\n",
            "Action Input: [\n",
            "  {\"slide_title\": \"Introduction to Supervised Fine-tuning\", \"content\": \"Supervised fine-tuning techniques involve adapting pre-trained language models (LLMs) to specific tasks using labeled data. *Add an image illustrating the concept of Supervised Fine-tuning from one of the suggested image sources.\"},\n",
            "  {\"slide_title\": \"Definition\", \"content\": \"Supervised fine-tuning, or SFT, involves adapting a pre-trained machine learning model to a specific task using labeled data. This process helps the model learn from examples that are directly relevant to the task at hand. *Add an image illustrating the concept of Supervised Fine-tuning from one of the suggested image sources.\"},\n",
            "  {\"slide_title\": \"Purpose\", \"content\": \"The main goal of supervised fine-tuning is to enhance the model's performance by teaching it new skills or improving its ability to make predictions based on the labeled data provided. *Add an image illustrating the learning process of a model from one of the suggested image sources.\"},\n",
            "  {\"slide_title\": \"Process\", \"content\": \"During fine-tuning, the model's weights and biases are adjusted using a smaller set of labeled data. This customization allows the model to better fit the specific requirements of the task it is being fine-tuned for. *Add an image illustrating the fine-tuning process from one of the suggested image sources.\"},\n",
            "  {\"slide_title\": \"Applications\", \"content\": \"Supervised fine-tuning is widely used in various applications, including image classification, natural language processing, and other machine learning tasks where labeled data is available. *Add an image illustrating some of these applications from one of the suggested image sources.\"},\n",
            "  {\"slide_title\": \"Resources for Additional Learning\", \"content\": \"For further reading and detailed methodologies, here are some resources you can explore: *Add an image representing continued learning or a book from one of the suggested image sources.* \\n\\n - [Supervised Fine Tuning: Enhancing Your LLM Accuracy](https://labelyourdata.com/articles/llm-fine-tuning/supervised-fine-tuning) \\n - [What is Supervised Fine-Tuning? Overview and Techniques - Sapien](https://www.sapien.io/blog/what-is-supervised-fine-tuning-overview-and-techniques) \\n - [Introduction to tuning | Generative AI | Google Cloud](https://cloud.google.com/vertex-ai/generative-ai/docs/models/tune-models) \\n - [What is Fine-Tuning? | IBM](https://www.ibm.com/think/topics/fine-tuning) \\n - [Supervised Fine Tuning - Lark](https://www.larksuite.com/en_us/topics/ai-glossary/supervised-fine-tuning) \\n - [Supervised Fine Tuning with Gemini 1.5 Pro for Image Captioning](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/tuning/supervised_finetuning_using_gemini_on_image_data.ipynb) \\n - [About supervised fine-tuning for Gemini models | Generative AI](https://cloud.google.com/vertex-ai/generative-ai/docs/models/gemini-supervised-tuning) \\n - [Fine-tuning - OpenAI API](https://platform.openai.com/docs/guides/fine-tuning) \\n - [Explanation: Supervised Fine-Tuning & Reinforcement Learning](https://medium.com/@joonbeomkwon/understanding-ai-training-supervised-fine-tuning-vs-reinforcement-learning-from-human-feedback-55d1b65317e0) \\n - [Fine-Tuning the CLIP Foundation Model for Image Classification](https://www.alexanderthamm.com/en/blog/fine-tuning-the-clip-foundation-model-for-image-classification/)\"}\n",
            "]\n",
            "================================================================================\n",
            "Calling Slide Generation Tool with slide_content TYPE :<class 'list'>\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"The presentation deck on 'Supervised Fine-tuning' has been successfully created and saved as 'presentation.pptx'. Please add appropriate images manually to the slides from one of the suggested sources.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for message in agent.messages:\n",
        "  print(message[\"content\"])\n",
        "  print(\"=\"*80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90OeHd3g32CY",
        "outputId": "d5380d84-f2f4-44fe-8981-5fd94c226836"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Answer the following questions as best you can. You have access to the following tools:\n",
            "\n",
            "Tool: code_generation_and_execution_tool\n",
            "Description: a coding tool that can take a prompt and generate executable python code. it parses and executes the code. returns the code and the error if the code execution fails.\n",
            "Arg: a single string parameter describing the coding task.\n",
            "\n",
            "\n",
            "Tool: ares_internet_search_tool\n",
            "Description: tool to search real-time relevant content from the internet\n",
            "Arg: a single string parameter that will be searched on the internet to find relevant content\n",
            "\n",
            "\n",
            "Tool: youtube_search_tool\n",
            "Description: a tool capable of searching the internet for youtube videos and returns the text transcript of the videos\n",
            "Arg: a single string parameter that will be searched on the internet to find relevant content\n",
            "\n",
            "\n",
            "Tool: slide_generation_tool\n",
            "Description: a tool that can create a pptx deck for a content. it takes a list of dictionaries. each list dictionary item represents a slide in the presentation. each dictionary item must have two keys: 'slide_title' and 'content'.\n",
            "Arg: list[dict[slide_title, content]]. ensure the action input is json parseable so i can convert it to required format\n",
            "\n",
            "\n",
            "Use the following format:\n",
            "\n",
            "Question: the input question you must answer\n",
            "Thought: you should always think about what to do\n",
            "Action: the action to take, should be one of [code_generation_and_execution_tool, ares_internet_search_tool, youtube_search_tool, slide_generation_tool]\n",
            "Action Input: the input to the action\n",
            "Observation: the result of the action\n",
            "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
            "Thought: I now know the final answer\n",
            "Final Answer: the final answer to the original input question\n",
            "\n",
            "Begin!\n",
            "\n",
            "================================================================================\n",
            "Generate a presentation deck on Supervised Fine-tuning\n",
            "================================================================================\n",
            "Thought: To generate a presentation deck, I first need to gather content on the topic 'Supervised Fine-tuning'. I can use the ares_internet_search_tool to find relevant information.\n",
            "Action: ares_internet_search_tool\n",
            "Action Input: \"Supervised Fine-tuning\"\n",
            "================================================================================\n",
            "Observation: Supervised fine-tuning techniques involve adapting pre-trained language models (LLMs) to specific tasks using labeled data. Here are some key techniques and insights related to supervised fine-tuning:\n",
            "\n",
            "1. **Basic Hyperparameter Tuning**: This involves adjusting the model's hyperparameters to optimize performance on the specific task. It is a fundamental approach that can significantly impact the model's effectiveness.\n",
            "\n",
            "2. **Training on Labeled Datasets**: Supervised fine-tuning requires a dataset with labeled examples that correspond to the desired outputs for the specific task. This helps the model learn the correct associations between inputs and outputs.\n",
            "\n",
            "3. **Task-Specific Adaptation**: The process allows developers to modify LLMs to align their outputs with specific use cases, enhancing the model's accuracy and relevance for particular applications.\n",
            "\n",
            "4. **Comparison with Other Techniques**: Supervised fine-tuning is often compared to other methods like prompt engineering and retrieval-augmented generation, highlighting its effectiveness in certain scenarios.\n",
            "\n",
            "5. **Parameter-Efficient Fine-Tuning**: This approach focuses on fine-tuning only a subset of the model's parameters, which can lead to improved performance while reducing computational costs.\n",
            "\n",
            "6. **Best Practices**: Implementing best practices in supervised fine-tuning, such as careful selection of the training dataset and iterative evaluation, can lead to better outcomes.\n",
            "\n",
            "For more detailed information, you can explore the following resources:\n",
            "- [Supervised Fine-tuning: customizing LLMs | by Juan Martinez](https://medium.com/mantisnlp/supervised-fine-tuning-customizing-llms-a2c1edbf22c3)\n",
            "- [Understanding and Using Supervised Fine-Tuning (SFT) for ...](https://cameronrwolfe.substack.com/p/understanding-and-using-supervised)\n",
            "- [What is Supervised Fine-Tuning? Overview and Techniques - Sapien](https://www.sapien.io/blog/what-is-supervised-fine-tuning-overview-and-techniques)\n",
            "- [Fine-Tuning LLMs: Supervised Fine-Tuning and Reward Modelling](https://huggingface.co/blog/rishiraj/finetune-llms)\n",
            "- [What is supervised fine-tuning in LLMs? Unveiling the process](https://nebius.com/blog/posts/fine-tuning/supervised-fine-tuning)\n",
            "- [Fine-Tuning LLMs: Overview, Methods & Best Practices - Turing](https://www.turing.com/resources/finetuning-large-language-models)\n",
            "- [Supervised Fine Tuning for Gemini LLM | Google Cloud Blog](https://cloud.google.com/blog/products/ai-machine-learning/supervised-fine-tuning-for-gemini-llm)\n",
            "- [Supervised fine-tuning (SFT) - Klu.ai](https://klu.ai/glossary/supervised-fine-tuning)\n",
            "- [Fine-tuning large language models (LLMs) in 2024 - SuperAnnotate](https://www.superannotate.com/blog/llm-fine-tuning)\n",
            "- [Supervised Fine Tuning: Enhancing Your LLM Accuracy](https://labelyourdata.com/articles/llm-fine-tuning/supervised-fine-tuning)\n",
            "================================================================================\n",
            "Thought: Now that I have collected the information to be included in the deck, I can use the slide_generation_tool to create the presentation.\n",
            "Action: slide_generation_tool\n",
            "Action Input: [\n",
            "  {\"slide_title\": \"Introduction to Supervised Fine-tuning\", \"content\": \"Supervised fine-tuning techniques involve adapting pre-trained language models (LLMs) to specific tasks using labeled data.\"},\n",
            "  {\"slide_title\": \"Basic Hyperparameter Tuning\", \"content\": \"This involves adjusting the model's hyperparameters to optimize performance on the specific task. It is a fundamental approach that can significantly impact the model's effectiveness.\"},\n",
            "  {\"slide_title\": \"Training on Labeled Datasets\", \"content\": \"Supervised fine-tuning requires a dataset with labeled examples that correspond to the desired outputs for the specific task. This helps the model learn the correct associations between inputs and outputs.\"},\n",
            "  {\"slide_title\": \"Task-Specific Adaptation\", \"content\": \"The process allows developers to modify LLMs to align their outputs with specific use cases, enhancing the model's accuracy and relevance for particular applications.\"},\n",
            "  {\"slide_title\": \"Comparison with Other Techniques\", \"content\": \"Supervised fine-tuning is often compared to other methods like prompt engineering and retrieval-augmented generation, highlighting its effectiveness in certain scenarios.\"},\n",
            "  {\"slide_title\": \"Parameter-Efficient Fine-Tuning\", \"content\": \"This approach focuses on fine-tuning only a subset of the model's parameters, which can lead to improved performance while reducing computational costs.\"},\n",
            "  {\"slide_title\": \"Best Practices in Supervised Fine-Tuning\", \"content\": \"Implementing best practices, such as careful selection of the training dataset and iterative evaluation, can lead to better outcomes.\"},\n",
            "  {\"slide_title\": \"Additional Resources\", \"content\": \"[Link1](https://medium.com/mantisnlp/supervised-fine-tuning-customizing-llms-a2c1edbf22c3), [Link2](https://cameronrwolfe.substack.com/p/understanding-and-using-supervised), [Link3](https://www.sapien.io/blog/what-is-supervised-fine-tuning-overview-and-techniques), [Link4](https://huggingface.co/blog/rishiraj/finetune-llms), [Link5](https://nebius.com/blog/posts/fine-tuning/supervised-fine-tuning), [Link6](https://www.turing.com/resources/finetuning-large-language-models), [Link7](https://cloud.google.com/blog/products/ai-machine-learning/supervised-fine-tuning-for-gemini-llm)\"}\n",
            "]\n",
            "================================================================================\n",
            "Observation: Presentation saved as 'presentation.pptx'.\n",
            "================================================================================\n",
            "Thought: I have successfully created the presentation deck on 'Supervised Fine-tuning'.\n",
            "Final Answer: The presentation deck on 'Supervised Fine-tuning' has been successfully created and saved as 'presentation.pptx'.\n",
            "================================================================================\n",
            "Generate a presentation deck on Supervised Fine-tuning. Add relevant images where applicable\n",
            "================================================================================\n",
            "Thought: To generate a presentation deck with relevant images, I first need to gather content and find suitable images on the topic 'Supervised Fine-tuning'. I will start by using the ares_internet_search_tool to find relevant information and images.\n",
            "Action: ares_internet_search_tool\n",
            "Action Input: \"Supervised Fine-tuning images\"\n",
            "================================================================================\n",
            "Observation: **Supervised Fine-Tuning Images**\n",
            "\n",
            "Supervised fine-tuning is the process of improving a pre-trained model's performance by training it on a labeled dataset. This method aligns the model with specific tasks or objectives, enhancing its accuracy and reliability for targeted applications. \n",
            "\n",
            "Key points about supervised fine-tuning include:\n",
            "\n",
            "1. **Definition**: Supervised fine-tuning, or SFT, involves adapting a pre-trained machine learning model to a specific task using labeled data. This process helps the model learn from examples that are directly relevant to the task at hand.\n",
            "\n",
            "2. **Purpose**: The main goal of supervised fine-tuning is to enhance the model's performance by teaching it new skills or improving its ability to make predictions based on the labeled data provided.\n",
            "\n",
            "3. **Process**: During fine-tuning, the model's weights and biases are adjusted using a smaller set of labeled data. This customization allows the model to better fit the specific requirements of the task it is being fine-tuned for.\n",
            "\n",
            "4. **Applications**: Supervised fine-tuning is widely used in various applications, including image classification, natural language processing, and other machine learning tasks where labeled data is available.\n",
            "\n",
            "5. **Resources**: For further reading and detailed methodologies, you can explore the following resources:\n",
            "   - [Supervised Fine Tuning: Enhancing Your LLM Accuracy](https://labelyourdata.com/articles/llm-fine-tuning/supervised-fine-tuning) (Nov 20, 2024)\n",
            "   - [What is Supervised Fine-Tuning? Overview and Techniques - Sapien](https://www.sapien.io/blog/what-is-supervised-fine-tuning-overview-and-techniques)\n",
            "   - [Introduction to tuning | Generative AI | Google Cloud](https://cloud.google.com/vertex-ai/generative-ai/docs/models/tune-models)\n",
            "   - [What is Fine-Tuning? | IBM](https://www.ibm.com/think/topics/fine-tuning)\n",
            "   - [Supervised Fine Tuning - Lark](https://www.larksuite.com/en_us/topics/ai-glossary/supervised-fine-tuning)\n",
            "   - [Supervised Fine Tuning with Gemini 1.5 Pro for Image Captioning](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/tuning/supervised_finetuning_using_gemini_on_image_data.ipynb)\n",
            "   - [About supervised fine-tuning for Gemini models | Generative AI](https://cloud.google.com/vertex-ai/generative-ai/docs/models/gemini-supervised-tuning)\n",
            "   - [Fine-tuning - OpenAI API](https://platform.openai.com/docs/guides/fine-tuning)\n",
            "   - [Explanation: Supervised Fine-Tuning & Reinforcement Learning](https://medium.com/@joonbeomkwon/understanding-ai-training-supervised-fine-tuning-vs-reinforcement-learning-from-human-feedback-55d1b65317e0)\n",
            "   - [Fine-Tuning the CLIP Foundation Model for Image Classification](https://www.alexanderthamm.com/en/blog/fine-tuning-the-clip-foundation-model-for-image-classification/)\n",
            "\n",
            "These resources provide comprehensive insights into the techniques and applications of supervised fine-tuning in machine learning.\n",
            "================================================================================\n",
            "Thought: Now that I have collected the information to be included in the deck, I can use the slide_generation_tool to create the presentation. However, to include relevant images, I'll search for freely usable images that I can manually add to the slides.\n",
            "Action: ares_internet_search_tool\n",
            "Action Input: \"Freely usable images for Supervised Fine-Tuning presentation\"\n",
            "================================================================================\n",
            "Observation: For your request for freely usable images for a Supervised Fine-Tuning presentation, here are some resources you can explore:\n",
            "\n",
            "1. **Pixabay**: \n",
            "   - Title: 3,000+ Free Fine-Tuning & Fine Art Images\n",
            "   - Description: 3,708 free images of fine-tuning available for download. These images are royalty-free and can be used in your projects.\n",
            "   - Link: [Pixabay Fine-Tuning Images](https://pixabay.com/images/search/fine-tuning/)\n",
            "\n",
            "2. **Shutterstock**: \n",
            "   - Title: Ai Fine Tuning: Over 105 Royalty-Free Licensable Stock Illustrations\n",
            "   - Description: Offers 105 AI fine-tuning illustrations, drawings, stickers, and clip-art available for download. \n",
            "   - Link: [Shutterstock AI Fine Tuning Illustrations](https://www.shutterstock.com/search/ai-fine-tuning?image_type=illustration)\n",
            "\n",
            "3. **iStock**: \n",
            "   - Title: Fine Tuning Pictures, Images and Stock Photos\n",
            "   - Description: Browse over 224,900 fine-tuning stock photos and images. You can search for specific concepts related to fine-tuning.\n",
            "   - Link: [iStock Fine Tuning Images](https://www.istockphoto.com/photos/fine-tuning)\n",
            "\n",
            "4. **Adobe Stock**: \n",
            "   - Title: Fine-Tune Images\n",
            "   - Description: Search from thousands of royalty-free fine-tune stock images and videos for your next project.\n",
            "   - Link: [Adobe Stock Fine-Tune Images](https://stock.adobe.com/search?k=fine-tune)\n",
            "\n",
            "These resources should provide a variety of images suitable for your presentation on supervised fine-tuning.\n",
            "================================================================================\n",
            "Thought: Now that I have a source for images, I can now create the slide deck. Note: the actual image embedding will have to be carried out manually as my capabilities as an AI assistant currently do not enable handling dynamic image data. In each slide description, I will add a note where the user can add an image from the suggested sources. \n",
            "Action: slide_generation_tool\n",
            "Action Input: [\n",
            "  {\"slide_title\": \"Introduction to Supervised Fine-tuning\", \"content\": \"Supervised fine-tuning techniques involve adapting pre-trained language models (LLMs) to specific tasks using labeled data. *Add an image illustrating the concept of Supervised Fine-tuning from one of the suggested image sources.\"},\n",
            "  {\"slide_title\": \"Definition\", \"content\": \"Supervised fine-tuning, or SFT, involves adapting a pre-trained machine learning model to a specific task using labeled data. This process helps the model learn from examples that are directly relevant to the task at hand. *Add an image illustrating the concept of Supervised Fine-tuning from one of the suggested image sources.\"},\n",
            "  {\"slide_title\": \"Purpose\", \"content\": \"The main goal of supervised fine-tuning is to enhance the model's performance by teaching it new skills or improving its ability to make predictions based on the labeled data provided. *Add an image illustrating the learning process of a model from one of the suggested image sources.\"},\n",
            "  {\"slide_title\": \"Process\", \"content\": \"During fine-tuning, the model's weights and biases are adjusted using a smaller set of labeled data. This customization allows the model to better fit the specific requirements of the task it is being fine-tuned for. *Add an image illustrating the fine-tuning process from one of the suggested image sources.\"},\n",
            "  {\"slide_title\": \"Applications\", \"content\": \"Supervised fine-tuning is widely used in various applications, including image classification, natural language processing, and other machine learning tasks where labeled data is available. *Add an image illustrating some of these applications from one of the suggested image sources.\"},\n",
            "  {\"slide_title\": \"Resources for Additional Learning\", \"content\": \"For further reading and detailed methodologies, here are some resources you can explore: *Add an image representing continued learning or a book from one of the suggested image sources.* \\n\\n - [Supervised Fine Tuning: Enhancing Your LLM Accuracy](https://labelyourdata.com/articles/llm-fine-tuning/supervised-fine-tuning) \\n - [What is Supervised Fine-Tuning? Overview and Techniques - Sapien](https://www.sapien.io/blog/what-is-supervised-fine-tuning-overview-and-techniques) \\n - [Introduction to tuning | Generative AI | Google Cloud](https://cloud.google.com/vertex-ai/generative-ai/docs/models/tune-models) \\n - [What is Fine-Tuning? | IBM](https://www.ibm.com/think/topics/fine-tuning) \\n - [Supervised Fine Tuning - Lark](https://www.larksuite.com/en_us/topics/ai-glossary/supervised-fine-tuning) \\n - [Supervised Fine Tuning with Gemini 1.5 Pro for Image Captioning](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/tuning/supervised_finetuning_using_gemini_on_image_data.ipynb) \\n - [About supervised fine-tuning for Gemini models | Generative AI](https://cloud.google.com/vertex-ai/generative-ai/docs/models/gemini-supervised-tuning) \\n - [Fine-tuning - OpenAI API](https://platform.openai.com/docs/guides/fine-tuning) \\n - [Explanation: Supervised Fine-Tuning & Reinforcement Learning](https://medium.com/@joonbeomkwon/understanding-ai-training-supervised-fine-tuning-vs-reinforcement-learning-from-human-feedback-55d1b65317e0) \\n - [Fine-Tuning the CLIP Foundation Model for Image Classification](https://www.alexanderthamm.com/en/blog/fine-tuning-the-clip-foundation-model-for-image-classification/)\"}\n",
            "]\n",
            "================================================================================\n",
            "Observation: Presentation saved as 'presentation.pptx'.\n",
            "================================================================================\n",
            "Thought: I have successfully created the presentation deck on 'Supervised Fine-tuning'. The user can now manually insert the images based on the suggestions made in each slide.\n",
            "Final Answer: The presentation deck on 'Supervised Fine-tuning' has been successfully created and saved as 'presentation.pptx'. Please add appropriate images manually to the slides from one of the suggested sources.\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test 2"
      ],
      "metadata": {
        "id": "RC5TEevQ32wk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "agent(\"⁠Generate a chart comparing Nvidia stock to Google. Save the graph as comparison.png file. Execute the code using code engine\")"
      ],
      "metadata": {
        "id": "LANfebExjPP-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "outputId": "4f9df3df-d170-42f3-a6e4-a48a2f540a06"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "Thought: To generate a chart comparing Nvidia stock to Google, I'll need to use a finance data library like 'yfinance' to fetch the stock data. Then, I can use a data visualization library like 'matplotlib' to generate the chart. We save the graph as 'comparison.png' file. Let's create the prompt for the code_generation_and_execution_tool.\n",
            "Action: code_generation_and_execution_tool\n",
            "Action Input: \"Generate a chart comparing Nvidia stock to Google and save the graph as 'comparison.png' file using Python\"\n",
            "================================================================================\n",
            "Calling Code Generaton Tool with the prompt: Generate a chart comparing Nvidia stock to Google and save the graph as 'comparison.png' file using Python\n",
            "Requires PIP package installations\n",
            "Installing packages: ['yfinance', 'matplotlib']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  2 of 2 completed"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Executing main code...\n",
            "Error executing generated code: 'Adj Close'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "Thought: The code executed has caused an error. The 'Adj Close' column might not be available or there could be other issues with fetching or processing the stock data. Let me adjust the code to use 'Close' instead and aim to handle any possible fetch or processing issues.\n",
            "Action: code_generation_and_execution_tool\n",
            "Action Input: \"Generate a chart comparing Nvidia stock to Google using 'Close' price and save the graph as 'comparison.png' file using Python\"\n",
            "================================================================================\n",
            "Calling Code Generaton Tool with the prompt: Generate a chart comparing Nvidia stock to Google using 'Close' price and save the graph as 'comparison.png' file using Python\n",
            "Requires PIP package installations\n",
            "Installing packages: ['yfinance', 'matplotlib']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Executing main code...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"The chart comparing Nvidia stock to Google has been successfully generated and saved as 'comparison.png'.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for message in agent.messages:\n",
        "  print(message[\"content\"])\n",
        "  print(\"=\"*80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WMSnqpTBuQjF",
        "outputId": "a7aff9e4-cc50-4752-cf15-ba4b68ec7d3d"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Answer the following questions as best you can. You have access to the following tools:\n",
            "\n",
            "Tool: code_generation_and_execution_tool\n",
            "Description: a coding tool that can take a prompt and generate executable python code. it parses and executes the code. returns the code and the error if the code execution fails.\n",
            "Arg: a single string parameter describing the coding task.\n",
            "\n",
            "\n",
            "Tool: ares_internet_search_tool\n",
            "Description: tool to search real-time relevant content from the internet\n",
            "Arg: a single string parameter that will be searched on the internet to find relevant content\n",
            "\n",
            "\n",
            "Tool: youtube_search_tool\n",
            "Description: a tool capable of searching the internet for youtube videos and returns the text transcript of the videos\n",
            "Arg: a single string parameter that will be searched on the internet to find relevant content\n",
            "\n",
            "\n",
            "Tool: slide_generation_tool\n",
            "Description: a tool that can create a pptx deck for a content. it takes a list of dictionaries. each list dictionary item represents a slide in the presentation. each dictionary item must have two keys: 'slide_title' and 'content'.\n",
            "Arg: list[dict[slide_title, content]]. ensure the action input is json parseable so i can convert it to required format\n",
            "\n",
            "\n",
            "Use the following format:\n",
            "\n",
            "Question: the input question you must answer\n",
            "Thought: you should always think about what to do\n",
            "Action: the action to take, should be one of [code_generation_and_execution_tool, ares_internet_search_tool, youtube_search_tool, slide_generation_tool]\n",
            "Action Input: the input to the action\n",
            "Observation: the result of the action\n",
            "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
            "Thought: I now know the final answer\n",
            "Final Answer: the final answer to the original input question\n",
            "\n",
            "Begin!\n",
            "\n",
            "================================================================================\n",
            "Generate a presentation deck on Supervised Fine-tuning\n",
            "================================================================================\n",
            "Thought: To generate a presentation deck, I first need to gather content on the topic 'Supervised Fine-tuning'. I can use the ares_internet_search_tool to find relevant information.\n",
            "Action: ares_internet_search_tool\n",
            "Action Input: \"Supervised Fine-tuning\"\n",
            "================================================================================\n",
            "Observation: Supervised fine-tuning techniques involve adapting pre-trained language models (LLMs) to specific tasks using labeled data. Here are some key techniques and insights related to supervised fine-tuning:\n",
            "\n",
            "1. **Basic Hyperparameter Tuning**: This involves adjusting the model's hyperparameters to optimize performance on the specific task. It is a fundamental approach that can significantly impact the model's effectiveness.\n",
            "\n",
            "2. **Training on Labeled Datasets**: Supervised fine-tuning requires a dataset with labeled examples that correspond to the desired outputs for the specific task. This helps the model learn the correct associations between inputs and outputs.\n",
            "\n",
            "3. **Task-Specific Adaptation**: The process allows developers to modify LLMs to align their outputs with specific use cases, enhancing the model's accuracy and relevance for particular applications.\n",
            "\n",
            "4. **Comparison with Other Techniques**: Supervised fine-tuning is often compared to other methods like prompt engineering and retrieval-augmented generation, highlighting its effectiveness in certain scenarios.\n",
            "\n",
            "5. **Parameter-Efficient Fine-Tuning**: This approach focuses on fine-tuning only a subset of the model's parameters, which can lead to improved performance while reducing computational costs.\n",
            "\n",
            "6. **Best Practices**: Implementing best practices in supervised fine-tuning, such as careful selection of the training dataset and iterative evaluation, can lead to better outcomes.\n",
            "\n",
            "For more detailed information, you can explore the following resources:\n",
            "- [Supervised Fine-tuning: customizing LLMs | by Juan Martinez](https://medium.com/mantisnlp/supervised-fine-tuning-customizing-llms-a2c1edbf22c3)\n",
            "- [Understanding and Using Supervised Fine-Tuning (SFT) for ...](https://cameronrwolfe.substack.com/p/understanding-and-using-supervised)\n",
            "- [What is Supervised Fine-Tuning? Overview and Techniques - Sapien](https://www.sapien.io/blog/what-is-supervised-fine-tuning-overview-and-techniques)\n",
            "- [Fine-Tuning LLMs: Supervised Fine-Tuning and Reward Modelling](https://huggingface.co/blog/rishiraj/finetune-llms)\n",
            "- [What is supervised fine-tuning in LLMs? Unveiling the process](https://nebius.com/blog/posts/fine-tuning/supervised-fine-tuning)\n",
            "- [Fine-Tuning LLMs: Overview, Methods & Best Practices - Turing](https://www.turing.com/resources/finetuning-large-language-models)\n",
            "- [Supervised Fine Tuning for Gemini LLM | Google Cloud Blog](https://cloud.google.com/blog/products/ai-machine-learning/supervised-fine-tuning-for-gemini-llm)\n",
            "- [Supervised fine-tuning (SFT) - Klu.ai](https://klu.ai/glossary/supervised-fine-tuning)\n",
            "- [Fine-tuning large language models (LLMs) in 2024 - SuperAnnotate](https://www.superannotate.com/blog/llm-fine-tuning)\n",
            "- [Supervised Fine Tuning: Enhancing Your LLM Accuracy](https://labelyourdata.com/articles/llm-fine-tuning/supervised-fine-tuning)\n",
            "================================================================================\n",
            "Thought: Now that I have collected the information to be included in the deck, I can use the slide_generation_tool to create the presentation.\n",
            "Action: slide_generation_tool\n",
            "Action Input: [\n",
            "  {\"slide_title\": \"Introduction to Supervised Fine-tuning\", \"content\": \"Supervised fine-tuning techniques involve adapting pre-trained language models (LLMs) to specific tasks using labeled data.\"},\n",
            "  {\"slide_title\": \"Basic Hyperparameter Tuning\", \"content\": \"This involves adjusting the model's hyperparameters to optimize performance on the specific task. It is a fundamental approach that can significantly impact the model's effectiveness.\"},\n",
            "  {\"slide_title\": \"Training on Labeled Datasets\", \"content\": \"Supervised fine-tuning requires a dataset with labeled examples that correspond to the desired outputs for the specific task. This helps the model learn the correct associations between inputs and outputs.\"},\n",
            "  {\"slide_title\": \"Task-Specific Adaptation\", \"content\": \"The process allows developers to modify LLMs to align their outputs with specific use cases, enhancing the model's accuracy and relevance for particular applications.\"},\n",
            "  {\"slide_title\": \"Comparison with Other Techniques\", \"content\": \"Supervised fine-tuning is often compared to other methods like prompt engineering and retrieval-augmented generation, highlighting its effectiveness in certain scenarios.\"},\n",
            "  {\"slide_title\": \"Parameter-Efficient Fine-Tuning\", \"content\": \"This approach focuses on fine-tuning only a subset of the model's parameters, which can lead to improved performance while reducing computational costs.\"},\n",
            "  {\"slide_title\": \"Best Practices in Supervised Fine-Tuning\", \"content\": \"Implementing best practices, such as careful selection of the training dataset and iterative evaluation, can lead to better outcomes.\"},\n",
            "  {\"slide_title\": \"Additional Resources\", \"content\": \"[Link1](https://medium.com/mantisnlp/supervised-fine-tuning-customizing-llms-a2c1edbf22c3), [Link2](https://cameronrwolfe.substack.com/p/understanding-and-using-supervised), [Link3](https://www.sapien.io/blog/what-is-supervised-fine-tuning-overview-and-techniques), [Link4](https://huggingface.co/blog/rishiraj/finetune-llms), [Link5](https://nebius.com/blog/posts/fine-tuning/supervised-fine-tuning), [Link6](https://www.turing.com/resources/finetuning-large-language-models), [Link7](https://cloud.google.com/blog/products/ai-machine-learning/supervised-fine-tuning-for-gemini-llm)\"}\n",
            "]\n",
            "================================================================================\n",
            "Observation: Presentation saved as 'presentation.pptx'.\n",
            "================================================================================\n",
            "Thought: I have successfully created the presentation deck on 'Supervised Fine-tuning'.\n",
            "Final Answer: The presentation deck on 'Supervised Fine-tuning' has been successfully created and saved as 'presentation.pptx'.\n",
            "================================================================================\n",
            "Generate a presentation deck on Supervised Fine-tuning. Add relevant images where applicable\n",
            "================================================================================\n",
            "Thought: To generate a presentation deck with relevant images, I first need to gather content and find suitable images on the topic 'Supervised Fine-tuning'. I will start by using the ares_internet_search_tool to find relevant information and images.\n",
            "Action: ares_internet_search_tool\n",
            "Action Input: \"Supervised Fine-tuning images\"\n",
            "================================================================================\n",
            "Observation: **Supervised Fine-Tuning Images**\n",
            "\n",
            "Supervised fine-tuning is the process of improving a pre-trained model's performance by training it on a labeled dataset. This method aligns the model with specific tasks or objectives, enhancing its accuracy and reliability for targeted applications. \n",
            "\n",
            "Key points about supervised fine-tuning include:\n",
            "\n",
            "1. **Definition**: Supervised fine-tuning, or SFT, involves adapting a pre-trained machine learning model to a specific task using labeled data. This process helps the model learn from examples that are directly relevant to the task at hand.\n",
            "\n",
            "2. **Purpose**: The main goal of supervised fine-tuning is to enhance the model's performance by teaching it new skills or improving its ability to make predictions based on the labeled data provided.\n",
            "\n",
            "3. **Process**: During fine-tuning, the model's weights and biases are adjusted using a smaller set of labeled data. This customization allows the model to better fit the specific requirements of the task it is being fine-tuned for.\n",
            "\n",
            "4. **Applications**: Supervised fine-tuning is widely used in various applications, including image classification, natural language processing, and other machine learning tasks where labeled data is available.\n",
            "\n",
            "5. **Resources**: For further reading and detailed methodologies, you can explore the following resources:\n",
            "   - [Supervised Fine Tuning: Enhancing Your LLM Accuracy](https://labelyourdata.com/articles/llm-fine-tuning/supervised-fine-tuning) (Nov 20, 2024)\n",
            "   - [What is Supervised Fine-Tuning? Overview and Techniques - Sapien](https://www.sapien.io/blog/what-is-supervised-fine-tuning-overview-and-techniques)\n",
            "   - [Introduction to tuning | Generative AI | Google Cloud](https://cloud.google.com/vertex-ai/generative-ai/docs/models/tune-models)\n",
            "   - [What is Fine-Tuning? | IBM](https://www.ibm.com/think/topics/fine-tuning)\n",
            "   - [Supervised Fine Tuning - Lark](https://www.larksuite.com/en_us/topics/ai-glossary/supervised-fine-tuning)\n",
            "   - [Supervised Fine Tuning with Gemini 1.5 Pro for Image Captioning](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/tuning/supervised_finetuning_using_gemini_on_image_data.ipynb)\n",
            "   - [About supervised fine-tuning for Gemini models | Generative AI](https://cloud.google.com/vertex-ai/generative-ai/docs/models/gemini-supervised-tuning)\n",
            "   - [Fine-tuning - OpenAI API](https://platform.openai.com/docs/guides/fine-tuning)\n",
            "   - [Explanation: Supervised Fine-Tuning & Reinforcement Learning](https://medium.com/@joonbeomkwon/understanding-ai-training-supervised-fine-tuning-vs-reinforcement-learning-from-human-feedback-55d1b65317e0)\n",
            "   - [Fine-Tuning the CLIP Foundation Model for Image Classification](https://www.alexanderthamm.com/en/blog/fine-tuning-the-clip-foundation-model-for-image-classification/)\n",
            "\n",
            "These resources provide comprehensive insights into the techniques and applications of supervised fine-tuning in machine learning.\n",
            "================================================================================\n",
            "Thought: Now that I have collected the information to be included in the deck, I can use the slide_generation_tool to create the presentation. However, to include relevant images, I'll search for freely usable images that I can manually add to the slides.\n",
            "Action: ares_internet_search_tool\n",
            "Action Input: \"Freely usable images for Supervised Fine-Tuning presentation\"\n",
            "================================================================================\n",
            "Observation: For your request for freely usable images for a Supervised Fine-Tuning presentation, here are some resources you can explore:\n",
            "\n",
            "1. **Pixabay**: \n",
            "   - Title: 3,000+ Free Fine-Tuning & Fine Art Images\n",
            "   - Description: 3,708 free images of fine-tuning available for download. These images are royalty-free and can be used in your projects.\n",
            "   - Link: [Pixabay Fine-Tuning Images](https://pixabay.com/images/search/fine-tuning/)\n",
            "\n",
            "2. **Shutterstock**: \n",
            "   - Title: Ai Fine Tuning: Over 105 Royalty-Free Licensable Stock Illustrations\n",
            "   - Description: Offers 105 AI fine-tuning illustrations, drawings, stickers, and clip-art available for download. \n",
            "   - Link: [Shutterstock AI Fine Tuning Illustrations](https://www.shutterstock.com/search/ai-fine-tuning?image_type=illustration)\n",
            "\n",
            "3. **iStock**: \n",
            "   - Title: Fine Tuning Pictures, Images and Stock Photos\n",
            "   - Description: Browse over 224,900 fine-tuning stock photos and images. You can search for specific concepts related to fine-tuning.\n",
            "   - Link: [iStock Fine Tuning Images](https://www.istockphoto.com/photos/fine-tuning)\n",
            "\n",
            "4. **Adobe Stock**: \n",
            "   - Title: Fine-Tune Images\n",
            "   - Description: Search from thousands of royalty-free fine-tune stock images and videos for your next project.\n",
            "   - Link: [Adobe Stock Fine-Tune Images](https://stock.adobe.com/search?k=fine-tune)\n",
            "\n",
            "These resources should provide a variety of images suitable for your presentation on supervised fine-tuning.\n",
            "================================================================================\n",
            "Thought: Now that I have a source for images, I can now create the slide deck. Note: the actual image embedding will have to be carried out manually as my capabilities as an AI assistant currently do not enable handling dynamic image data. In each slide description, I will add a note where the user can add an image from the suggested sources. \n",
            "Action: slide_generation_tool\n",
            "Action Input: [\n",
            "  {\"slide_title\": \"Introduction to Supervised Fine-tuning\", \"content\": \"Supervised fine-tuning techniques involve adapting pre-trained language models (LLMs) to specific tasks using labeled data. *Add an image illustrating the concept of Supervised Fine-tuning from one of the suggested image sources.\"},\n",
            "  {\"slide_title\": \"Definition\", \"content\": \"Supervised fine-tuning, or SFT, involves adapting a pre-trained machine learning model to a specific task using labeled data. This process helps the model learn from examples that are directly relevant to the task at hand. *Add an image illustrating the concept of Supervised Fine-tuning from one of the suggested image sources.\"},\n",
            "  {\"slide_title\": \"Purpose\", \"content\": \"The main goal of supervised fine-tuning is to enhance the model's performance by teaching it new skills or improving its ability to make predictions based on the labeled data provided. *Add an image illustrating the learning process of a model from one of the suggested image sources.\"},\n",
            "  {\"slide_title\": \"Process\", \"content\": \"During fine-tuning, the model's weights and biases are adjusted using a smaller set of labeled data. This customization allows the model to better fit the specific requirements of the task it is being fine-tuned for. *Add an image illustrating the fine-tuning process from one of the suggested image sources.\"},\n",
            "  {\"slide_title\": \"Applications\", \"content\": \"Supervised fine-tuning is widely used in various applications, including image classification, natural language processing, and other machine learning tasks where labeled data is available. *Add an image illustrating some of these applications from one of the suggested image sources.\"},\n",
            "  {\"slide_title\": \"Resources for Additional Learning\", \"content\": \"For further reading and detailed methodologies, here are some resources you can explore: *Add an image representing continued learning or a book from one of the suggested image sources.* \\n\\n - [Supervised Fine Tuning: Enhancing Your LLM Accuracy](https://labelyourdata.com/articles/llm-fine-tuning/supervised-fine-tuning) \\n - [What is Supervised Fine-Tuning? Overview and Techniques - Sapien](https://www.sapien.io/blog/what-is-supervised-fine-tuning-overview-and-techniques) \\n - [Introduction to tuning | Generative AI | Google Cloud](https://cloud.google.com/vertex-ai/generative-ai/docs/models/tune-models) \\n - [What is Fine-Tuning? | IBM](https://www.ibm.com/think/topics/fine-tuning) \\n - [Supervised Fine Tuning - Lark](https://www.larksuite.com/en_us/topics/ai-glossary/supervised-fine-tuning) \\n - [Supervised Fine Tuning with Gemini 1.5 Pro for Image Captioning](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/tuning/supervised_finetuning_using_gemini_on_image_data.ipynb) \\n - [About supervised fine-tuning for Gemini models | Generative AI](https://cloud.google.com/vertex-ai/generative-ai/docs/models/gemini-supervised-tuning) \\n - [Fine-tuning - OpenAI API](https://platform.openai.com/docs/guides/fine-tuning) \\n - [Explanation: Supervised Fine-Tuning & Reinforcement Learning](https://medium.com/@joonbeomkwon/understanding-ai-training-supervised-fine-tuning-vs-reinforcement-learning-from-human-feedback-55d1b65317e0) \\n - [Fine-Tuning the CLIP Foundation Model for Image Classification](https://www.alexanderthamm.com/en/blog/fine-tuning-the-clip-foundation-model-for-image-classification/)\"}\n",
            "]\n",
            "================================================================================\n",
            "Observation: Presentation saved as 'presentation.pptx'.\n",
            "================================================================================\n",
            "Thought: I have successfully created the presentation deck on 'Supervised Fine-tuning'. The user can now manually insert the images based on the suggestions made in each slide.\n",
            "Final Answer: The presentation deck on 'Supervised Fine-tuning' has been successfully created and saved as 'presentation.pptx'. Please add appropriate images manually to the slides from one of the suggested sources.\n",
            "================================================================================\n",
            "⁠Generate a chart comparing Nvidia stock to Google. Save the graph as comparison.png file. Execute the code using code engine\n",
            "================================================================================\n",
            "Thought: To generate a chart comparing Nvidia stock to Google, I'll need to use a finance data library like 'yfinance' to fetch the stock data. Then, I can use a data visualization library like 'matplotlib' to generate the chart. We save the graph as 'comparison.png' file. Let's create the prompt for the code_generation_and_execution_tool.\n",
            "Action: code_generation_and_execution_tool\n",
            "Action Input: \"Generate a chart comparing Nvidia stock to Google and save the graph as 'comparison.png' file using Python\"\n",
            "================================================================================\n",
            "Observation: Code: # pip install yfinance matplotlib\n",
            "import yfinance as yf\n",
            "import matplotlib.pyplot as plt\n",
            "\n",
            "# Define the stock tickers for Nvidia and Google\n",
            "tickers = ['NVDA', 'GOOGL']\n",
            "\n",
            "# Download historical stock data for the past year\n",
            "data = yf.download(tickers, start='2022-10-01', end='2023-10-01')['Adj Close']\n",
            "\n",
            "# Plot the stock data\n",
            "plt.figure(figsize=(12, 6))\n",
            "for ticker in tickers:\n",
            "    plt.plot(data[ticker], label=ticker)\n",
            "\n",
            "# Add labels and title\n",
            "plt.title('Nvidia vs Google Stock Prices (Past Year)')\n",
            "plt.xlabel('Date')\n",
            "plt.ylabel('Adjusted Close Price')\n",
            "plt.legend()\n",
            "\n",
            "# Save the plot to a file\n",
            "plt.savefig('comparison.png')\n",
            "\n",
            "Code execution caused an error: 'Adj Close'\n",
            "================================================================================\n",
            "Thought: The code executed has caused an error. The 'Adj Close' column might not be available or there could be other issues with fetching or processing the stock data. Let me adjust the code to use 'Close' instead and aim to handle any possible fetch or processing issues.\n",
            "Action: code_generation_and_execution_tool\n",
            "Action Input: \"Generate a chart comparing Nvidia stock to Google using 'Close' price and save the graph as 'comparison.png' file using Python\"\n",
            "================================================================================\n",
            "Observation: Code: # pip install yfinance matplotlib\n",
            "import yfinance as yf\n",
            "import matplotlib.pyplot as plt\n",
            "\n",
            "# Define the stock symbols\n",
            "nvidia_symbol = 'NVDA'\n",
            "google_symbol = 'GOOGL'\n",
            "\n",
            "# Download the data\n",
            "nvidia_data = yf.download(nvidia_symbol, start='2023-01-01', end='2023-12-31')\n",
            "google_data = yf.download(google_symbol, start='2023-01-01', end='2023-12-31')\n",
            "\n",
            "# Plot the 'Close' prices\n",
            "plt.figure(figsize=(14, 7))\n",
            "plt.plot(nvidia_data.index, nvidia_data['Close'], label='Nvidia (NVDA)', color='green')\n",
            "plt.plot(google_data.index, google_data['Close'], label='Google (GOOGL)', color='blue')\n",
            "\n",
            "# Add labels and title\n",
            "plt.title('Nvidia vs Google Stock Price (2023)')\n",
            "plt.xlabel('Date')\n",
            "plt.ylabel('Close Price (USD)')\n",
            "plt.legend()\n",
            "\n",
            "# Save the plot\n",
            "plt.savefig('comparison.png')\n",
            "plt.close()\n",
            "\n",
            "\n",
            "Code Executed Successfully\n",
            "================================================================================\n",
            "Thought: Now I have successfully generated the chart comparing Nvidia stock to Google and saved the image as 'comparison.png'. \n",
            "Final Answer: The chart comparing Nvidia stock to Google has been successfully generated and saved as 'comparison.png'.\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test 3"
      ],
      "metadata": {
        "id": "SULqPDfv4PfB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "agent(\"Make me a diet plan by searching YouTube videos about keto diet\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "CZ9mXTbf4O5B",
        "outputId": "e831d2e6-7b57-41db-df31-ffbdc4ffa287"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "Thought: The best way to get information about keto diet from YouTube is by searching for the term \"keto diet plan\". This will provide you video transcripts related to the topic.\n",
            "Action: youtube_search_tool\n",
            "Action Input: \"keto diet plan\"\n",
            "================================================================================\n",
            "Calling YouTube Search Tool with prompt: keto diet plan\n",
            "Error getting transcript: \n",
            "Could not retrieve a transcript for the video https://www.youtube.com/watch?v=3ggnRpM_mXc! This is most likely caused by:\n",
            "\n",
            "Subtitles are disabled for this video\n",
            "\n",
            "If you are sure that the described cause is not responsible for this error and that a transcript should be retrievable, please create an issue at https://github.com/jdepoix/youtube-transcript-api/issues. Please add which version of youtube_transcript_api you are using and provide the information needed to replicate the error. Also make sure that there are no open issues which already describe your problem!\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Based on the YouTube video transcripts, here is a simple Ketogenic diet plan:\\n\\n**Meal Ideas:**\\n1. **Breakfast**: Eggs cooked in olive oil and half an avocado.\\n2. **Lunch**: Grilled salmon with a side of celery sticks dipped in almond butter.\\n3. **Dinner**: Grass-fed beef burger (without the bun) and a side salad.\\n4. **Snack**: A handful of macadamia nuts.\\n\\n**Remember:**\\n - Maintain a high-fat, moderate-protein, and very low-carb diet.\\n - Macros should usually consist of 70-80% fats, 15-20% protein, and 5-10% carbs.\\n - Keep track of intake and stay aware of hydration needs.\\n - Regular physical activity promotes better results.\\n - Regularly test ketone levels to ensure you are in ketosis.\\n - Prepare meals in advance to cope with busy schedules or challenging days.\\n - Avoid carb indulgence and focus on nutrient-dense, whole foods.\\n\\nDo make sure to consult with a healthcare professional before starting any new diet regimen. Remember, this is a general plan and might need modifications depending upon individual health conditions and requirements.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for message in agent.messages:\n",
        "  print(message[\"content\"])\n",
        "  print(\"=\"*80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r96EDaf_4Ta7",
        "outputId": "df1e8e4b-41a7-44e5-ffd7-ae047d936b3a"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Answer the following questions as best you can. You have access to the following tools:\n",
            "\n",
            "Tool: code_generation_and_execution_tool\n",
            "Description: a coding tool that can take a prompt and generate executable python code. it parses and executes the code. returns the code and the error if the code execution fails.\n",
            "Arg: a single string parameter describing the coding task.\n",
            "\n",
            "\n",
            "Tool: ares_internet_search_tool\n",
            "Description: tool to search real-time relevant content from the internet\n",
            "Arg: a single string parameter that will be searched on the internet to find relevant content\n",
            "\n",
            "\n",
            "Tool: youtube_search_tool\n",
            "Description: a tool capable of searching the internet for youtube videos and returns the text transcript of the videos\n",
            "Arg: a single string parameter that will be searched on the internet to find relevant content\n",
            "\n",
            "\n",
            "Tool: slide_generation_tool\n",
            "Description: a tool that can create a pptx deck for a content. it takes a list of dictionaries. each list dictionary item represents a slide in the presentation. each dictionary item must have two keys: 'slide_title' and 'content'.\n",
            "Arg: list[dict[slide_title, content]]. ensure the action input is json parseable so i can convert it to required format\n",
            "\n",
            "\n",
            "Use the following format:\n",
            "\n",
            "Question: the input question you must answer\n",
            "Thought: you should always think about what to do\n",
            "Action: the action to take, should be one of [code_generation_and_execution_tool, ares_internet_search_tool, youtube_search_tool, slide_generation_tool]\n",
            "Action Input: the input to the action\n",
            "Observation: the result of the action\n",
            "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
            "Thought: I now know the final answer\n",
            "Final Answer: the final answer to the original input question\n",
            "\n",
            "Begin!\n",
            "\n",
            "================================================================================\n",
            "Generate a presentation deck on Supervised Fine-tuning\n",
            "================================================================================\n",
            "Thought: Before generating a presentation, I need to gather detailed and accurate content about Supervised Fine-tuning. An internet search for content related to \"Supervised Fine-tuning\" seems to be the best action.\n",
            "Action: ares_internet_search_tool\n",
            "Action Input: \"Supervised Fine-tuning\"\n",
            "================================================================================\n",
            "Observation: Supervised fine-tuning techniques involve adapting pre-trained language models (LLMs) to specific tasks using labeled data. Here are some key points and techniques related to supervised fine-tuning:\n",
            "\n",
            "1. **Definition**: Supervised fine-tuning (SFT) is the process of training a pre-trained LLM on a labeled dataset to improve its performance on specific downstream tasks.\n",
            "\n",
            "2. **Purpose**: The main goal of SFT is to align the model's outputs with particular use cases, enhancing its ability to perform tasks such as language translation, sentiment analysis, and text generation.\n",
            "\n",
            "3. **Common Techniques**:\n",
            "   - **Basic Hyperparameter Tuning**: This involves adjusting parameters like learning rate, batch size, and number of epochs to optimize model performance.\n",
            "   - **Data Augmentation**: Enhancing the training dataset with additional examples or variations to improve model robustness.\n",
            "   - **Transfer Learning**: Utilizing knowledge gained from one task to improve performance on another related task.\n",
            "   - **Regularization Techniques**: Implementing methods like dropout or weight decay to prevent overfitting during training.\n",
            "\n",
            "4. **Applications**: SFT is widely used in various applications, including chatbots, recommendation systems, and any domain where specific language understanding is required.\n",
            "\n",
            "5. **Resources for Further Reading**:\n",
            "   - [Supervised Fine-tuning: customizing LLMs](https://medium.com/mantisnlp/supervised-fine-tuning-customizing-llms-a2c1edbf22c3)\n",
            "   - [Understanding and Using Supervised Fine-Tuning (SFT)](https://cameronrwolfe.substack.com/p/understanding-and-using-supervised)\n",
            "   - [What is supervised fine-tuning in LLMs? Unveiling the process](https://nebius.com/blog/posts/fine-tuning/supervised-fine-tuning)\n",
            "   - [What is Supervised Fine-Tuning? Overview and Techniques - Sapien](https://www.sapien.io/blog/what-is-supervised-fine-tuning-overview-and-techniques)\n",
            "   - [Fine-Tuning LLMs: Supervised Fine-Tuning and Reward Modelling](https://huggingface.co/blog/rishiraj/finetune-llms)\n",
            "   - [Supervised fine-tuning (SFT) - Klu.ai](https://klu.ai/glossary/supervised-fine-tuning)\n",
            "   - [Fine-Tuning LLMs: Overview, Methods & Best Practices - Turing](https://www.turing.com/resources/finetuning-large-language-models)\n",
            "   - [Supervised Fine Tuning for Gemini LLM | Google Cloud Blog](https://cloud.google.com/blog/products/ai-machine-learning/supervised-fine-tuning-for-gemini-llm)\n",
            "   - [Fine-tuning large language models (LLMs) in 2024 - SuperAnnotate](https://www.superannotate.com/blog/llm-fine-tuning)\n",
            "   - [Fine-Tuning LLMs: A Guide With Examples - DataCamp](https://www.datacamp.com/tutorial/fine-tuning-large-language-models)\n",
            "================================================================================\n",
            "Thought: Now that I have gathered some information on Supervised Fine-tuning, I can use this information to create a presentation deck. I will organize it into several slides, each with a clear focus and content based on the information gathered.\n",
            "Action: slide_generation_tool\n",
            "Action Input: [\n",
            "    {\"slide_title\": \"Introduction to Supervised Fine-tuning\", \"content\": \"Supervised fine-tuning (SFT) is the process of training a pre-trained LLM on a labeled dataset to improve its performance on specific downstream tasks. Its main goal is to align the model's outputs with particular use cases, enhancing its ability to perform tasks such as language translation, sentiment analysis, and text generation.\"},\n",
            "    {\"slide_title\": \"Common Techniques\", \"content\": \"Basic Hyperparameter Tuning, Data Augmentation, Transfer Learning, Regularization Techniques. These techniques involve adjusting parameters, enhancing the training dataset, utilizing knowledge gained, and implementing methods to optimize model performance.\"},\n",
            "    {\"slide_title\": \"Applications of Supervised Fine-tuning\", \"content\": \"SFT is widely used in various applications, including chatbots, recommendation systems, and any domain where specific language understanding is required.\"},\n",
            "    {\"slide_title\": \"Resources for Further Reading\", \"content\": \"For more detailed knowledge and understanding of Supervised Fine-tuning, refer to the following online resources...\"}\n",
            "]\n",
            "================================================================================\n",
            "Observation: Presentation saved as 'presentation.pptx'.\n",
            "================================================================================\n",
            "Thought: I have successfully created a presentation deck on \"Supervised Fine-tuning\" based on the information gathered.\n",
            "Final Answer: The presentation deck on \"Supervised Fine-tuning\" has been successfully generated and saved as 'presentation.pptx'.\n",
            "================================================================================\n",
            "⁠Generate a chart comparing Nvidia stock to Google. Save the graph as comparison.png file. Execute the code using code engine\n",
            "================================================================================\n",
            "Thought: To generate a chart comparing the stocks of Nvidia and Google, we will need to pull the stock data for both companies. For this, we can use Python with libraries like pandas, yfinance (to get the stock data), and matplotlib (for plotting the data). We'll need to code this and execute it using the code generation and execution tool.\n",
            "Action: code_generation_and_execution_tool\n",
            "Action Input: \"Generate a comparison chart for Nvidia and Google stock and save as comparison.png\"\n",
            "================================================================================\n",
            "Observation: Code: # pip install yfinance matplotlib\n",
            "import yfinance as yf\n",
            "import matplotlib.pyplot as plt\n",
            "\n",
            "# Define the stock tickers\n",
            "nvidia_ticker = \"NVDA\"\n",
            "google_ticker = \"GOOGL\"\n",
            "\n",
            "# Download stock data\n",
            "nvidia_data = yf.download(nvidia_ticker, start=\"2023-01-01\", end=\"2023-10-31\")\n",
            "google_data = yf.download(google_ticker, start=\"2023-01-01\", end=\"2023-10-31\")\n",
            "\n",
            "# Plot the data\n",
            "plt.figure(figsize=(14, 7))\n",
            "plt.plot(nvidia_data.index, nvidia_data['Close'], label='Nvidia (NVDA)', color='green')\n",
            "plt.plot(google_data.index, google_data['Close'], label='Google (GOOGL)', color='blue')\n",
            "\n",
            "# Add labels and title\n",
            "plt.title('Nvidia vs Google Stock Price Comparison (2023)')\n",
            "plt.xlabel('Date')\n",
            "plt.ylabel('Stock Price (USD)')\n",
            "plt.legend()\n",
            "\n",
            "# Save the chart as a PNG file\n",
            "plt.savefig('comparison.png')\n",
            "plt.close()\n",
            "\n",
            "\n",
            "Code Executed Successfully\n",
            "================================================================================\n",
            "Thought: The code executed successfully and the plot comparing Nvidia and Google's stock was saved as 'comparison.png'. Therefore, the graph is ready.\n",
            "Final Answer: A comparison graph of Nvidia and Google's stock has been successfully generated and saved as 'comparison.png'.\n",
            "================================================================================\n",
            "Make me a diet plan by searching YouTube videos about keto diet\n",
            "================================================================================\n",
            "Thought: The best way to get information about keto diet from YouTube is by searching for the term \"keto diet plan\". This will provide you video transcripts related to the topic.\n",
            "Action: youtube_search_tool\n",
            "Action Input: \"keto diet plan\"\n",
            "================================================================================\n",
            "Observation: Video Title: {'title': 'PSMF Egg Drop Soup with Shui Mai Dumplings | Carnivore Keto and PSMF Recipe', 'video_id': 'KywVkZgtBuM', 'description': 'PSMF Egg Drop Soup with Shui Mai Dumplings | Carnivore Keto and PSMF Recipe Basic PSMF dumpling recipe: 1 lb lean gr. chicken, 1/2 lb raw shrimp, 1/2 tsp salt, 1 tbs Red Boat fish sauce. Other seasonings as desired and tolerated. Form into 30 balls. Each ball: 36 calories, 5.25 g protein, 1.55 g fat, 0.2 total carb. How I make Bone Broth: https ...', 'link': 'https://www.youtube.com/watch?v=KywVkZgtBuM', 'duration': '16:37', 'publisher': 'YouTube', 'uploader': 'Ketogenic Woman', 'published': '2025-03-16T14:16:22.0000000', 'view_count': 1080, 'thumbnail': 'https://tse4.mm.bing.net/th?id=OVF.EdvbA7Pfmooz2VpbMX0JHg&pid=Api'}\n",
            "Content: Anita, a dedicated follower of a ketogenic diet, shares her take on Egg Drop Soup with Shumai (Chinese dumplings). She presents this recipe as extremely beneficial for those on a carnivore or protein-sparing modified fast diet. Her recipe includes one pound of ground chicken (or lean ground pork) and half a pound of raw shrimp. These form the base for the dumplings. Her choice of spices includes salt, garlic powder, onion powder, and white pepper. She also includes a half teaspoon each of salt, garlic powder, and onion powder. Her sauce incorporates redbat fish sauce—which consists only of anchovy and sea salt—for an authentic Asian flavor. Anita combines all these ingredients into bite-sized dumplings which she cooks in bone broth. She makes an egg-based soup from the broth used to cook the dumplings. The end result is a protein-packed meal suitable for meal prep, with each dumpling containing 36 calories, 5.25g of protein, 1.5g of fat, and 0.1g carbs.\n",
            "\n",
            "\n",
            "Video Title: {'title': 'How to Lose Weight with the Strict Keto Diet Plan?', 'video_id': '7iaA4mm4jO8', 'description': 'Want to shed pounds quickly and effectively? The Strict Keto Diet Plan might be the key to your weight loss success! In this video, we break down everything you need to know about the ketogenic diet, including: What is the Strict Keto Diet? How does keto help with fat loss? The best foods to eat and what to avoid Tips to stay in ketosis and ...', 'link': 'https://www.youtube.com/watch?v=7iaA4mm4jO8', 'duration': '7:28', 'publisher': 'YouTube', 'uploader': 'Well Extol', 'published': '2025-03-13T15:58:29.0000000', 'view_count': None, 'thumbnail': 'https://tse4.mm.bing.net/th?id=OVF.ATdQLxlG5mH2Fs1NyJcosw&pid=Api'}\n",
            "Content: The Strict Keto Diet plan is a highly efficient method for losing weight. Focusing on a high fat, moderate protein, and very low carbohydrate diet, it forces the body to enter a state called ketosis, where it uses fat for energy instead of carbohydrates. Such a diet regime is to be maintained strictly, with macros usually consisting of 70-80% fats, 15-20% protein, and 5-10% carbs. Processed food, artificial sweeteners, and hidden carbohydrates are largely excluded.\n",
            "The Strict Keto Diet promotes weight loss by inducing ketosis, suppressing appetite, improving insulin sensitivity, increasing fat burning, and reducing water weight. To implement it, one has to plan meals, track intake, stay aware of hydration needs, and incorporate physical activity. A sample meal plan might include nutrient-dense foods such as eggs, avocado, olive oil, macadamia nuts, grilled salmon, celery sticks with almond butter, and grass-fed beef burger.\n",
            "To sustain the diet, one must eliminate hidden carbs, measure portion sizes accurately, prepare meals in advance, regularly test ketone levels, avoid carb indulgences, and focus on nutrient-dense foods. Benefits of the Strict Keto diet are rapid weight loss, better mental clarity, improved energy levels, reduced inflammation, and better metabolic health. Challenges such as keto flu, social challenges, time-intensive meal preparation, and weight loss plateaus can be addressed with hydration, planning, and adjusting the diet or exercise routine as needed. The diet, although requiring dedication, offers rewarding outcomes in terms of health and weight loss.\n",
            "================================================================================\n",
            "Thought: Now that I have sourced information from ketogenic diet YouTube videos, I can create a basic diet plan using the details provided. It's important to note that before starting a new diet, consultation with a healthcare professional is advised.\n",
            "Final Answer: Based on the YouTube video transcripts, here is a simple Ketogenic diet plan:\n",
            "\n",
            "**Meal Ideas:**\n",
            "1. **Breakfast**: Eggs cooked in olive oil and half an avocado.\n",
            "2. **Lunch**: Grilled salmon with a side of celery sticks dipped in almond butter.\n",
            "3. **Dinner**: Grass-fed beef burger (without the bun) and a side salad.\n",
            "4. **Snack**: A handful of macadamia nuts.\n",
            "\n",
            "**Remember:**\n",
            " - Maintain a high-fat, moderate-protein, and very low-carb diet.\n",
            " - Macros should usually consist of 70-80% fats, 15-20% protein, and 5-10% carbs.\n",
            " - Keep track of intake and stay aware of hydration needs.\n",
            " - Regular physical activity promotes better results.\n",
            " - Regularly test ketone levels to ensure you are in ketosis.\n",
            " - Prepare meals in advance to cope with busy schedules or challenging days.\n",
            " - Avoid carb indulgence and focus on nutrient-dense, whole foods.\n",
            "\n",
            "Do make sure to consult with a healthcare professional before starting any new diet regimen. Remember, this is a general plan and might need modifications depending upon individual health conditions and requirements.\n",
            "================================================================================\n"
          ]
        }
      ]
    }
  ]
}